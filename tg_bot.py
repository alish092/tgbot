import os
import logging
import docx2txt
import tiktoken
from langchain.chat_models import ChatOpenAI
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
from tqdm import tqdm

# === ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ ===
TELEGRAM_TOKEN = "7634065162:AAFuAJnaRIX73PdMfjyDsYtYlpRcSNUf7a0"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
DOCS_FOLDER = "docs"
MAX_TOKENS_PER_BLOCK = 2000

# === ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ Ð›ÐžÐ“Ð“Ð•Ð Ð ===
logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)

# === ÐšÐžÐ”ÐžÐ’ÐÐ¯ Ð‘ÐÐ—Ð ===
encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
SYNONYMS = {
    "Ð°Ñ‚Ð·": ["Ð°Ñ‚Ð·", "Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð»Ð°", "Ñ€ÐµÑÐµÐ¿ÑˆÐ½", "Ñ€ÐµÑÐµÐ¿ÑˆÐ¸Ð¾Ð½Ð¸ÑÑ‚", "Ð¿Ð¾Ñ€ÑˆÐµ Ñ…Ð¾ÑÑ‚", "Ñ…Ð¾ÑÑ‚"],
    "Ð¾Ñ‚Ñ‡ÐµÑ‚": ["Ð¾Ñ‚Ñ‡ÐµÑ‚", "Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ð¾ÑÑ‚ÑŒ", "Ð¾Ñ‚Ñ‡Ñ‘Ñ‚", "Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ñ‹Ð¹", "Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ†Ð¸Ñ", "ÑÐ´Ð°Ñ‡Ð° Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²", "Ð±Ð°Ð»Ð°Ð½Ñ"],
    "Ð½Ð°Ð»Ð¾Ð³": ["Ð½Ð°Ð»Ð¾Ð³", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ð°Ñ", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ð¹", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ð°Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ð¾ÑÑ‚ÑŒ", "Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ†Ð¸Ñ"],
    "Ð³Ð»Ð°Ð²Ð±ÑƒÑ…": ["Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ð³Ð». Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ"],
    "Ð·Ð°Ð¼ÐµÐ½ÑÑ‚ÑŒ": ["Ð·Ð°Ð¼ÐµÑ‰Ð°ÐµÑ‚", "Ð¸ÑÐ¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸", "Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸", "Ð¿Ð¾Ð´Ð¼ÐµÐ½ÑÐµÑ‚", "Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚"],
}

def num_tokens(text): return len(encoding.encode(text))

def load_docs():
    docs = []
    for filename in os.listdir(DOCS_FOLDER):
        if filename.endswith(".docx"):
            try:
                text = docx2txt.process(os.path.join(DOCS_FOLDER, filename))
                docs.append((filename, text))
            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² {filename}: {e}")
    return docs

def split_into_blocks(text):
    paragraphs = [p.strip() for p in text.split("\n\n") if len(p.strip()) > 0]
    blocks, current = [], ""
    for p in paragraphs:
        if num_tokens(current + "\n\n" + p) < MAX_TOKENS_PER_BLOCK:
            current += "\n\n" + p
        else:
            blocks.append(current.strip())
            current = p
    if current: blocks.append(current.strip())
    return blocks

def extract_keywords_from_question(question, synonyms):
    result = set()
    for word in question.lower().split():
        for key, values in synonyms.items():
            if word == key or word in values:
                result.update(values)
    return result

def is_relevant_block(block, question, synonyms):
    keywords = extract_keywords_from_question(question, synonyms)
    return any(k in block.lower() for k in keywords)

def ask_gpt(block, question):
    prompt = f"""
Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¿Ð¾ Ñ€ÐµÐ³Ð»Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð¼. ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚.
Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° â€” Ð½Ð°Ð¿Ð¸ÑˆÐ¸: "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚".

Ð¢ÐµÐºÑÑ‚:
{block}

Ð’Ð¾Ð¿Ñ€Ð¾Ñ: {question}
ÐžÑ‚Ð²ÐµÑ‚:
"""
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2, max_tokens=1000)
    return llm.invoke(prompt).content.strip()

def gpt_choose_best(question, answers):
    formatted = "\n\n".join(f"- {a}" for a in answers)
    prompt = f"""
Ð’Ð¾Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ: "{question}".

{formatted}

Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹, Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¸ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹. ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.
"""
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2)
    return llm.invoke(prompt).content.strip()

# === ÐžÐ‘Ð ÐÐ‘ÐžÐ¢Ð§Ð˜Ðš ===
async def ask(update: Update, context: ContextTypes.DEFAULT_TYPE):
    question = " ".join(context.args)
    if not question:
        await update.message.reply_text("â— Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹: /ask [Ð²Ð¾Ð¿Ñ€Ð¾Ñ]")
        return

    await update.message.reply_text("â³ Ð”ÑƒÐ¼Ð°ÑŽ...")

    docs = load_docs()
    answers = []

    for filename, text in tqdm(docs, desc="ðŸ“„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°"):
        blocks = split_into_blocks(text)
        for block in blocks:
            if not is_relevant_block(block, question, SYNONYMS):
                continue
            answer = ask_gpt(block, question)
            if "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚" not in answer.lower():
                answers.append((answer, block))

    if not answers:
        for filename, text in docs:
            short_text = text[:12000]
            answer = ask_gpt(short_text, question)
            if "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚" not in answer.lower():
                await update.message.reply_text(f"ðŸ“‚ {filename}\n\nâœ… ÐžÑ‚Ð²ÐµÑ‚:\n{answer}")
                return
        await update.message.reply_text("âŒ ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾.")
        return

    raw_answers = [a for a, _ in answers]
    best = gpt_choose_best(question, raw_answers)

    for ans, block in answers:
        if best.strip() in ans:
            await update.message.reply_text(f"âœ… ÐžÑ‚Ð²ÐµÑ‚:\n{best}\n\nðŸ“„ Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº:\n{block[:1000]}...")
            return

# === Ð—ÐÐŸÐ£Ð¡Ðš ===
if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("ask", ask))
    print("ðŸ¤– Telegram-Ð±Ð¾Ñ‚ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½. Ð–Ð´Ñƒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ /ask")
    app.run_polling()
