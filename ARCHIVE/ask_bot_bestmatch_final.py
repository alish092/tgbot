import os
import docx2txt
import tiktoken
from langchain.chat_models import ChatOpenAI
from tqdm import tqdm
import httpx
import asyncio

DOCS_FOLDER = "docs"
MAX_TOKENS_PER_BLOCK = 2000
encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
docs = []

# Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ð¾Ð² Ð¸ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²
synonyms_from_db = {
    "Ð°Ñ‚Ð·": ["Ð°Ñ‚Ð·", "Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð»Ð°", "Ñ€ÐµÑÐµÐ¿ÑˆÐ½", "Ñ€ÐµÑÐµÐ¿ÑˆÐ¸Ð¾Ð½Ð¸ÑÑ‚", "Ð¿Ð¾Ñ€ÑˆÐµ Ñ…Ð¾ÑÑ‚", "Ñ…Ð¾ÑÑ‚"],
    "Ð¾Ñ‚Ñ‡ÐµÑ‚": ["Ð¾Ñ‚Ñ‡ÐµÑ‚", "Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ð¾ÑÑ‚ÑŒ", "Ð¾Ñ‚Ñ‡Ñ‘Ñ‚", "Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ñ‹Ð¹", "Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ†Ð¸Ñ", "ÑÐ´Ð°Ñ‡Ð° Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²", "Ð±Ð°Ð»Ð°Ð½Ñ"],
    "Ð½Ð°Ð»Ð¾Ð³": ["Ð½Ð°Ð»Ð¾Ð³", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ð°Ñ", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ð¹", "Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ð°Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ð¾ÑÑ‚ÑŒ", "Ð´ÐµÐºÐ»Ð°Ñ€Ð°Ñ†Ð¸Ñ"],
    "Ð³Ð»Ð°Ð²Ð±ÑƒÑ…": ["Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ð³Ð». Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€", "Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ"],
    "Ð·Ð°Ð¼ÐµÐ½ÑÑ‚ÑŒ": ["Ð·Ð°Ð¼ÐµÑ‰Ð°ÐµÑ‚", "Ð¸ÑÐ¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸", "Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸", "Ð¿Ð¾Ð´Ð¼ÐµÐ½ÑÐµÑ‚", "Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚"],
}
async def fetch_synonyms_from_backend():
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get("http://localhost:8000/synonyms_from_db")
            response.raise_for_status()
            data = response.json()
            synonyms_map = {}
            for item in data:
                keyword = item["keyword"].lower()
                syn = item["synonym"].lower()
                synonyms_map.setdefault(keyword, []).append(syn)
            return synonyms_map
    except Exception as e:
        print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ñ‹: {e}")
        return {}
# Ð¢Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ñ
def num_tokens(text):
    return len(encoding.encode(text))

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
def load_docs():
    docs = []
    for filename in os.listdir(DOCS_FOLDER):
        if filename.endswith(".docx"):
            try:
                text = docx2txt.process(os.path.join(DOCS_FOLDER, filename))
                docs.append((filename, text))
            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² {filename}: {e}")
    return docs

# Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð°Ð±Ð·Ð°Ñ†Ð°Ð¼
def split_into_blocks(text):
    paragraphs = [p.strip() for p in text.split("\n\n") if len(p.strip()) > 0]
    blocks = []
    current = ""
    for p in paragraphs:
        if num_tokens(current + "\n\n" + p) < MAX_TOKENS_PER_BLOCK:
            current += "\n\n" + p
        else:
            blocks.append(current.strip())
            current = p
    if current:
        blocks.append(current.strip())
    return blocks

# Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ð°Ð¼Ð¸
def extract_keywords_from_question(question, synonyms_from_db):
    result = set()
    for word in question.lower().split():
        for key, values in synonyms.items():
            if word == key or word in values:
                result.update(values)
    return result

# Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð±Ð»Ð¾ÐºÐ¾Ð² Ð¿Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ ÑÐ»Ð¾Ð²Ð°Ð¼
def is_relevant_block(block, question, synonyms_from_db):
    keywords = extract_keywords_from_question(question, synonyms_from_db)
    return any(k in block.lower() for k in keywords)

# Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº GPT Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð±Ð»Ð¾ÐºÑƒ
def ask_gpt(block, question):
    prompt = f"""
Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¿Ð¾ Ñ€ÐµÐ³Ð»Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð¼. ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚.
Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° â€” Ð½Ð°Ð¿Ð¸ÑˆÐ¸: "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚".

Ð¢ÐµÐºÑÑ‚:
{block}

Ð’Ð¾Ð¿Ñ€Ð¾Ñ: {question}
ÐžÑ‚Ð²ÐµÑ‚:
"""
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2, max_tokens=1000)
    return llm.invoke(prompt).content.strip()

# Ð’Ñ‹Ð±Ð¾Ñ€ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°
def gpt_choose_best(question, answers):
    formatted = "\n\n".join(f"- {a}" for a in answers)
    prompt = f"""
Ð’Ð¾Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ: "{question}".

{formatted}

Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹, Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¸ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹. ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.
"""
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2)
    return llm.invoke(prompt).content.strip()

# Ð—Ð°Ð¿ÑƒÑÐº
def main():
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("âŒ Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ OPENAI_API_KEY")
        return

    global docs
    docs = load_docs()
    global synonyms_from_db
    synonyms_from_db = asyncio.run(fetch_synonyms_from_backend())
    print(f"ðŸ“¥ Ð¡Ð¸Ð½Ð¾Ð½Ð¸Ð¼Ñ‹ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹: {len(synonyms_from_db)} Ð³Ñ€ÑƒÐ¿Ð¿")
    while True:
        question = input("\nâ“ Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ (Ð¸Ð»Ð¸ 'exit'): ")
        if question.strip().lower() == "exit":
            print("ðŸ‘‹ Ð”Ð¾ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸!")
            break

        answers = []
        relevant_blocks = []

        for filename, text in tqdm(docs, desc="ðŸ“„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"):
            blocks = split_into_blocks(text)
            for block in blocks:
                if not is_relevant_block(block, question, synonyms_from_db):
                    continue
                    print(f"ðŸ§© Ð§Ð°Ð½Ðº:\n{block[:200]}...\n")

                answer = ask_gpt(block, question)
                if "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚" not in answer.lower():
                    answers.append((answer, block))

        if not answers:
            print("âš ï¸ ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ â€” Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð²ÐµÑÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚...")
            for filename, text in docs:
                short_text = text[:12000]
                answer = ask_gpt(short_text, question)
                if "Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½ÐµÑ‚" not in answer.lower():
                    print(f"\nâœ… ÐžÑ‚Ð²ÐµÑ‚ Ð¸Ð· Ð²ÑÐµÐ³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° ({filename}):\n{answer}")
                    break
            else:
                print("âŒ ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð°Ð¶Ðµ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ðµ.")
            continue

        # Ð’Ñ‹Ð±Ð¾Ñ€ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        raw_answers = [a for a, _ in answers]
        best = gpt_choose_best(question, raw_answers)
        print("\nâœ… Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚:\n", best)

        # ÐÐ°Ð¹Ð´Ñ‘Ð¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð±Ð»Ð¾Ðº
        for ans, block in answers:
            if best.strip() in ans:
                print("\nðŸ“„ Ð¤Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ GPT:\n")
                print(block[:1000], "...\n")
                break

if __name__ == "__main__":
    main()
